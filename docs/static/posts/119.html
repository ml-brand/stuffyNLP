<!doctype html>
<html lang="ru">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Душный NLP — пост #119</title>
  <meta name="description" content=" Соскучились по постерам с ICLR? Их есть у нас!   Свежая подборка интересных статей, чтобы скрасить вечер понедельника.    Knowledge Entropy Decay during Language Model Pretraining Hinders New Knowled" />
  <link rel="icon" href="../../favicon.ico" sizes="any" />
  <link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32.png" />
  <link rel="apple-touch-icon" href="../../apple-touch-icon.png" />

  <link rel="canonical" href="https://ml-brand.github.io/stuffyNLP/static/posts/119.html" />
  <meta property="og:type" content="article" />
  <meta property="og:title" content="Душный NLP — пост #119" />
  <meta property="og:description" content=" Соскучились по постерам с ICLR? Их есть у нас!   Свежая подборка интересных статей, чтобы скрасить вечер понедельника.    Knowledge Entropy Decay during Language Model Pretraining Hinders New Knowled" />
  <meta property="og:image" content="https://ml-brand.github.io/stuffyNLP/assets/media/thumbs/119_480.webp" />
  <meta property="og:image:alt" content="Душный NLP" />
  <meta property="article:published_time" content="2025-04-28T14:03:27+00:00" />
  <meta property="article:author" content="Душный NLP" />
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:image" content="https://ml-brand.github.io/stuffyNLP/assets/media/thumbs/119_480.webp" />
  <link rel="stylesheet" href="../../style.css" />
  <script src="../../metrika.js"></script>
</head>
<body data-index-href="../page-2.html">
  <header class="header">
    <div class="container">
      <div class="title-grid single-title">
        <a class="grid-avatar" href="#" target="_blank" rel="noopener">
          <img id="channelAvatar" class="channel-avatar" src="../../assets/channel_avatar.jpg" alt="Аватар канала"  />
        </a>
        <div class="grid-main">
          <div class="title-head">
            <a class="back-link" href="../page-2.html">← Ко всем постам</a>
            <a class="badge-chip" id="siteTitleWrap" href="#" target="_blank" rel="noopener"><h1 id="siteTitle">Душный NLP</h1></a>
            <div class="hero-actions">
              <a id="subscribeBtn" class="subscribe-btn" href="https://t.me/+1Z41UptsLwszZDE6" target="_blank" rel="noopener" >Подписаться</a>
              <a class="icon-btn" href="../../post.html?id=119" aria-label="Открыть динамическую страницу поста">↺</a>
              <button id="themeToggle" class="icon-btn" type="button" aria-label="Переключить тему"></button>
            </div>
          </div>
        </div>
      </div>
    </div>
  </header>

  
  <div id="promoBanner" class="promo-banner" hidden>
    <div class="container promo-inner">
      <span class="promo-text"><a href="https://t.me/addlist/5NH3RoVejEI1MGEy">Подпишись на все наши ML каналы. Они классные, отвечаем!</a></span>
      <button id="promoClose" class="promo-close" type="button" aria-label="Скрыть плашку">×</button>
    </div>
  </div>
  

  <main class="container single-page">
    <article id="postContainer" class="post post-page" data-post-id="119">
      <div class="post-header">
        <div class="right"><span class="post-date" data-iso-date="2025-04-28T14:03:27+00:00">2025-04-28 14:03 UTC</span></div>
      </div>
      <div class="post-body"><strong>Соскучились по постерам с ICLR? Их есть у нас!</strong><br><br>Свежая подборка интересных статей, чтобы скрасить вечер понедельника.<br><br><a href="https://arxiv.org/abs/2410.01380" rel="nofollow noopener noreferrer"><strong>Knowledge Entropy Decay during Language Model Pretraining Hinders New Knowledge Acquisition</strong></a><br><br>Интересная статья о забывании фактов. Известно, что факты хранятся в FF, но авторы посмотрели на динамику распределения весов в виде векторов, чтобы понять, почему плохо усваиваются знания после самого претрейна. Оказывается, всё распределение лежит в маленьком проценте векторов, и они сильно портятся от дообучения.<br><br><a href="https://arxiv.org/abs/2409.12917" rel="nofollow noopener noreferrer"><strong>Training Language Models to Self-Correct via Reinforcement Learning</strong></a><br><br>Вместо промптинга, файнтюнинга и использования отдельной модели авторы пытаются встроить self-correction в модель. Существующие решения либо требуют отдельных моделей для верификации, либо используют более крупные модели-учителя, либо страдают от проблем «смещения распределения» (модель исправляет чужие ошибки, но не свои) и «схлопывание поведения» (модель делает одинаковые попытки без реальной коррекции).<br><br>Авторы предлагают двустадийное решение задачи, где вторая попытка пытается исправлять ошибки первой.<br><br>Детали успеха:<br><br> — на первом этапе создается хорошая инициализация для RL c принуждением первой попытки быть близкой к базовой модели (KL-регуляризация);<br><br>— on-policy RL;<br><br>— модифицированный реворд, сравнивающий прогресс между попытками.<br><br><a href="https://arxiv.org/abs/2406.06874" rel="nofollow noopener noreferrer"><strong>Learning Reward and Policy Jointly from Demonstration and Preference Improves Alignment</strong></a><br><br>Статья о совместном обученим RL+SFT+RM. Всё в онлайне. Реворд учится не только преференсам, но ещё и поощрять экспертные демонстрации из SFT-датасета.<br>Лоссы довольно понятным образом можно вывести <br><br>В цикле:<br><br>— шаг обучения RM;<br>— несколько шагов PPO.<br><br><a href="https://arxiv.org/abs/2503.16672" rel="nofollow noopener noreferrer"><strong>Accelerating Transformer Inference and Training with 2:4 Activation Sparsity</strong></a><br><br>Авторы придумали как использовать sparse kernel в тренировке. Заменяют SwiGLU на Squared ReLU (утверждается, что без потери качества), и замечают, что после этого во втором матричном умножении появляется много нулей в активациях. Используют 2:4 sparse kernels для того, чтобы ускорить это умножение (зануляя активации, которые ломают 2:4 картинку).<br><br>На backward из-за того, что матрица транспонируется, приходится использовать пару трюков:<br><br> — разбивать матрицу на две части — «очень плотные строки (5%)» и «разреженные строки (95%)» — и делать два отдельных гемма; <br>— чтобы бороться с явлением «соседние токены часто либо одновременно нули, либо одновременно не нули» шафлят токены перед FFN, а потом шалят обратно;<br>— используют row-wise-квантизацию;<br>— получают x1.3 ускорение на FFN-блоках.<br><br>В статье почему-то описывают только 1.5B-перплексию, но говорят, что на 7B и downstream-задачах вроде тоже работает неплохо.<br><br><a href="https://arxiv.org/abs/2502.09974" rel="nofollow noopener noreferrer"><strong>Has My System Prompt Been Used? Large Language Model Prompt Membership Inference</strong></a><br><br>Инженеры Amazon предлагают довольно простую процедуру расчёта стат.теста для проверки, использует ли LLM новые вводные из системного промпта. Тест основывается на средних значениях бертовых эмбеддингов того текста, который сгенерировала LLM. По словам авторов, для статистической значимости даже на незначительных изменениях достаточно прогнать около 300 примеров для каждого промпта.<br><br><em>*Компания Meta признана экстремистской организацией в России.<br><br>Интересные постеры увидели </em><tg-emoji emoji-id="5224192932302565805">❣</tg-emoji><em> Екатерина Редина, Константин Бабалян, Павел Темирчев, Степан Каргальцев, Кирилл Никоров</em><br><br>#YaICLR<br><br><a href="https://t.me/+koZSGGNHwAk5M2E6" rel="nofollow noopener noreferrer">Душный NLP</a><div class="media"><img class="media-img" loading="lazy" src="../../assets/media/thumbs/119_480.webp" srcset="../../assets/media/thumbs/119_480.webp 480w, ../../assets/media/119.jpg 1200w" sizes="(max-width: 768px) 100vw, 800px" alt="" data-post-id="119" data-image-index="0" /><img class="media-img" loading="lazy" src="../../assets/media/thumbs/120_480.webp" srcset="../../assets/media/thumbs/120_480.webp 480w, ../../assets/media/120.jpg 1200w" sizes="(max-width: 768px) 100vw, 800px" alt="" data-post-id="119" data-image-index="1" /><img class="media-img" loading="lazy" src="../../assets/media/thumbs/121_480.webp" srcset="../../assets/media/thumbs/121_480.webp 480w, ../../assets/media/121.jpg 1200w" sizes="(max-width: 768px) 100vw, 800px" alt="" data-post-id="119" data-image-index="2" /><img class="media-img" loading="lazy" src="../../assets/media/thumbs/122_480.webp" srcset="../../assets/media/thumbs/122_480.webp 480w, ../../assets/media/122.jpg 1200w" sizes="(max-width: 768px) 100vw, 800px" alt="" data-post-id="119" data-image-index="3" /><img class="media-img" loading="lazy" src="../../assets/media/thumbs/123_480.webp" srcset="../../assets/media/thumbs/123_480.webp 480w, ../../assets/media/123.jpg 1200w" sizes="(max-width: 768px) 100vw, 800px" alt="" data-post-id="119" data-image-index="4" /></div></div>
      <div class="actions">
        <span>3 353 просмотров · 20 реакций</span>
        <span class="action-links"><a href="https://t.me/stuffyNLP/119" target="_blank" rel="noopener">Открыть в Telegram</a> · <a href="../page-2.html">К списку постов</a> · <a href="./119.html">Ссылка на этот пост</a></span>
      </div>
    </article>

    <div class="pager single-nav">
      <a id="prevPost" class="nav-link" href="./124.html" style="visibility:visible">← Более новый</a>
      <a id="nextPost" class="nav-link" href="./118.html" style="visibility:visible">Более старый →</a>
    </div>
  </main>

  <footer class="footer">
    <div class="container">
      <div class="footer-inner">
        <span>based on <a href="https://github.com/ml-brand/tg-to-gh-pages" target="_blank" rel="noopener">tg-to-gh-pages</a> (created by <a href="https://github.com/ml-brand" target="_blank" rel="noopener">ML Brand</a>)</span>
        <a id="repoLink" href="https://github.com/ml-brand/tg-to-gh-pages" target="_blank" rel="noopener">Do the same with your channel.</a>
        <span class="footer-links">
          static copy ·
          <a href="../../feed.xml" target="_blank" rel="noopener">RSS</a> ·
          <a href="../../atom.xml" target="_blank" rel="noopener">Atom</a>
        </span>
      </div>
    </div>
  </footer>

  <script>
    window.__STATIC_POSTS = [{"id": 119, "media": [{"kind": "photo", "path": "../../assets/media/119.jpg", "thumb": "../../assets/media/thumbs/119_480.webp", "size": 279366, "mime": "image/jpeg", "name": null}, {"kind": "photo", "path": "../../assets/media/120.jpg", "thumb": "../../assets/media/thumbs/120_480.webp", "size": 189381, "mime": "image/jpeg", "name": null}, {"kind": "photo", "path": "../../assets/media/121.jpg", "thumb": "../../assets/media/thumbs/121_480.webp", "size": 177847, "mime": "image/jpeg", "name": null}, {"kind": "photo", "path": "../../assets/media/122.jpg", "thumb": "../../assets/media/thumbs/122_480.webp", "size": 168900, "mime": "image/jpeg", "name": null}, {"kind": "photo", "path": "../../assets/media/123.jpg", "thumb": "../../assets/media/thumbs/123_480.webp", "size": 189255, "mime": "image/jpeg", "name": null}]}];
    window.__STATIC_META = {"title": "Душный NLP", "username": "stuffyNLP", "channel": "stuffyNLP", "last_sync_utc": "2026-02-14T14:05:09Z", "posts_count": 114, "last_seen_message_id": 226, "stats": {"new": 105, "updated": 1, "media_downloaded": 105}, "avatar": "assets/channel_avatar.jpg", "meta_schema_version": "1.0.0", "posts_schema_version": "1.0.0"};
  </script>
  <script src="../../common.js"></script>
  <script src="../../static.js"></script>
</body>
</html>
